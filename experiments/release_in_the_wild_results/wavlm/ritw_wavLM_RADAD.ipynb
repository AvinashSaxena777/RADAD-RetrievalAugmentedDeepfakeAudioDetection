{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# WavLM - Release-In-The-Wild - Retreival Augmented Framework for Deepfake Audio Detection"
      ],
      "metadata": {
        "id": "nzDZaKjpB_Zi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WavLM Based DeepFake Audio Detection\n",
        "\n",
        "* In this notebook, we are going to use WavLM based classifier which directly operated over raw audio for different tasks.\n",
        "* Here, we are going to use for deepfake audio detection\n",
        "\n",
        "\n",
        "### Summary of Key Processing Steps in WavLM\n",
        "1. Works directly on raw audio, allowing for easy input preparation.\n",
        "2. Utilizes convolutional layers for feature extraction followed by a Transformer encoder to capture global context in the audio.\n",
        "3. Gated Relative Position Bias: Enhances contextual understanding, which is especially useful in capturing anomalies or artifacts typical in deepfake audio.\n",
        "4. This process enables WavLM to excel in deepfake detection tasks by capturing nuanced patterns that distinguish real from synthetic audio, leveraging both local and global information in the audio signal."
      ],
      "metadata": {
        "id": "7EVgBhcKB_Zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "kPFd7GudB_Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from config import Config\n",
        "from dataset import AudioDataset\n",
        "import argparse\n",
        "import os\n",
        "from pipeline import DeepfakeDetectionPipeline\n",
        "import torch\n",
        "\n",
        "# ========================\n",
        "# Main runner (same behavior; wandb toggle)\n",
        "# ========================\n",
        "\"\"\"\n",
        "Run the complete audio deepfake detection pipeline with single-GPU optimizations.\n",
        "\"\"\"\n",
        "import argparse\n",
        "\n",
        "# 1. Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# 3. Disable problematic torchaudio backends\n",
        "os.environ[\"TORCHAUDIO_USE_SOX\"] = \"0\"\n",
        "os.environ[\"TORCHAUDIO_USE_BACKEND_DISPATCHER\"] = \"1\"\n",
        "\n",
        "# 4. Set device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.set_device(device)\n",
        "\n",
        "# 5. Create configuration\n",
        "config = Config()\n",
        "config.device = device\n",
        "\n",
        "config.train_split = 0.8\n",
        "mode = \"train\"\n",
        "audio_path = None\n",
        "config.feature_extractor_type = \"wavlm\"\n",
        "pipeline_check = False\n",
        "\n",
        "if pipeline_check:\n",
        "  config.data_fraction = 0.01\n",
        "  config.num_epochs = 2\n",
        "  # 5a. Wandb toggle\n",
        "  use_wandb = False  # set False to disable W&B\n",
        "else:\n",
        "  config.data_fraction = 1.0\n",
        "  config.num_epochs = 10\n",
        "  # 5a. Wandb toggle\n",
        "  use_wandb = True  # set False to disable W&B\n",
        "\n",
        "\n",
        "config.use_wandb = use_wandb\n",
        "\n",
        "# 6. DataLoader settings\n",
        "config.num_workers = max(1, torch.cuda.device_count() * 2)\n",
        "config.train_batch_size = getattr(config, \"train_batch_size\", 256)\n",
        "config.eval_batch_size = getattr(config, \"eval_batch_size\", 256)\n",
        "config.db_batch_size = getattr(config, \"db_batch_size\", 64)\n",
        "config.top_k = getattr(config, \"top_k\", 5)\n",
        "config.use_batch_norm = False\n",
        "config.use_layer_norm = True\n",
        "\n",
        "\n",
        "# 7. Initialize pipeline\n",
        "pipeline = DeepfakeDetectionPipeline(config)\n",
        "\n",
        "if mode == \"train\":\n",
        "    train_dataset = AudioDataset(config, is_train=True, split_data=True)\n",
        "    val_dataset   = AudioDataset(config, is_train=False, split_data=True)\n",
        "    pipeline.print_split_stats(train_dataset, \"Train\")\n",
        "    pipeline.print_split_stats(val_dataset,   \"Val\")\n",
        "    pipeline.train(train_dataset, val_dataset)\n",
        "\n",
        "elif mode == \"evaluate\":\n",
        "    config.use_wandb = False\n",
        "    pipeline.load_models(\"final_model\")\n",
        "    pipeline.vector_db.load()\n",
        "\n",
        "    test_dataset = AudioDataset(config, is_train=False, split_data=True)\n",
        "    if hasattr(pipeline, \"evaluate_with_metrics\"):\n",
        "        metrics = pipeline.evaluate_with_metrics(test_dataset)\n",
        "        print(\"Evaluation metrics:\")\n",
        "        for key, value in metrics.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "    else:\n",
        "        loss, acc = pipeline.evaluate(test_dataset)\n",
        "        print(f\"Eval Loss: {loss:.4f}, Eval Acc: {acc:.4f}\")\n",
        "\n",
        "elif mode == \"predict\":\n",
        "    if not audio_path:\n",
        "        raise ValueError(\"Audio path must be provided for predict mode\")\n",
        "    pipeline.load_models(\"best_model\")\n",
        "    pipeline.vector_db.load()\n",
        "    result = pipeline.predict(audio_path)\n",
        "    logging.info(f\"Prediction  : {result['prediction']}\")\n",
        "    logging.info(f\"Probability(bona-fide) : {result['probability_bonafide']:.4f}\")\n",
        "    logging.info(f\"Retrieved   : {result['retrieved_labels']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f2ccc9ab085747b78b1f4370f8756716",
            "970eb3afbf99498fbc1fda9570c15361",
            "3c63642422ca46f39ee077968255178e",
            "78dcc5b07a794122b76e71f22d5c2423",
            "4ce00add5d2f4945b55756bdf36972ea",
            "5c6b179a870c4ba0b0b85a74feb9c4ea",
            "41f1511bd26042aa8fc4e118d4525f02",
            "6c7b777d9e1b45e5865c547312aabc1b",
            "33a2cbbf342a48de8dec1617b856f139",
            "5b6eaddcbe064900a573ccacf2cf3ff8",
            "7b51f5fb06f44e82b5e08239d96f4f7c",
            "8ae2bef240c043c3b15ebe1d280bb876",
            "581186f52cb745ee9cc8569d9bea60cb",
            "92a6c2560d9b467fb213cb68ddeb34f2",
            "f2cc4c097a2043b6a79339a43452529a",
            "d3bfa220621e4954b755fa032b7d5878",
            "c5cde3ef57914004a13e40488a34da71",
            "5f794414067549ddb151ba741ea288f4",
            "7a113666239f4084bcd9f23dd9dc1af1",
            "fe0c16cae59a4519be8daca90fb030ae",
            "836c2135469646e5af015f5636e34953",
            "1790965a1fab4cb6ad5af0a5f611b607",
            "670cb5ee22834d31b800516244aa19ae",
            "2d42bb84a9994981aee1b64f0e200824",
            "f7a2ec695d2f4b37a2352cdc97d2e7d8",
            "6667b19998364fab91bb812ea4e63d8e",
            "6adba12272a246e7804e7d483b808b9e",
            "8848a426b7a34995b47c942507d767c6",
            "8f9d3d9c3ecf4849bb278f220d28308d",
            "5166fcf65d014f8087b819b745f0f478",
            "b43e578a864544fd8ecf5c044f0d9abc",
            "67e21ca65a5c40deb5df84b202156980",
            "db48791be0ee447e9429c02a39224f6d",
            "02c0617ec5ee4ef4b7a91a5a2684e390",
            "f0faf2cc3ab84a1f99b02967f2ab5551",
            "20bbdba7a78e4d50ba5c8632e1b7bec4",
            "05c0a40cdce94bdfaaa2c52e3ccc7c0a",
            "61c17719cdf24fd9ad6b0e1e1feb0646",
            "716e7d4f5e6a4101853003ab8e09d7ca",
            "38a79e690ab9440ab99ce7f12ef8163a",
            "55b501a0c1124da084bf3627bd7431b7",
            "8969acd1e7dc49ada8f40b1d8f68d3b9",
            "5e3148ac8f4e4e8f908bea64ffa1bdf9",
            "762c751d7e2d4bbbad456f8b6fc2e460",
            "db29d240139346988f86e383330ebd0e",
            "ccefea9a758a4a289928878c37dbff62",
            "ac26cd84d20e47b79ea9190d9cd2bf9f",
            "c04c1c51d162492a9fbd55856f1b11ee",
            "ba6d6a6f57c442fe94ef048b16df95b9",
            "88d6da3876bf4173a66585efbf175ca7",
            "e2193492c8e84932b8f4ac6e83fd61fc",
            "5da23398738e49a4b1e636f956b54e89",
            "80c92dfb900f4f2bad399de5a9b1842d",
            "ad13b171f4334a5cb377cbbfb26cdb9f",
            "2f219bd904504efda8080ea0965ffc05"
          ]
        },
        "id": "CyuELataCnIN",
        "outputId": "0bd4ad4f-e06e-4b22-b6a6-cf62f388b25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2ccc9ab085747b78b1f4370f8756716"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ae2bef240c043c3b15ebe1d280bb876"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "670cb5ee22834d31b800516244aa19ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/378M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02c0617ec5ee4ef4b7a91a5a2684e390"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature dimension set to: 768\n",
            "Train set → total: 25423, bonafide: 9453 (37.18%), spoof: 15970 (62.82%)\n",
            "Val set → total: 6356, bonafide: 2363 (37.18%), spoof: 3993 (62.82%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVector DB Build:   0%|          | 0/398 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db29d240139346988f86e383330ebd0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Vector DB Build: 100%|██████████| 398/398 [20:32<00:00,  3.10s/it]\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mavinash-saxena\u001b[0m (\u001b[33mavinash-saxena-san-jose-state-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251002_090115-ohw10zt7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf/runs/ohw10zt7' target=\"_blank\">colab-177b0ca59e53-1020</a></strong> to <a href='https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf' target=\"_blank\">https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf/runs/ohw10zt7' target=\"_blank\">https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf/runs/ohw10zt7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/10:   0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Epoch 1/10: 100%|██████████| 100/100 [19:58<00:00, 11.99s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [05:00<00:00, 12.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.8383, Train Acc: 0.5761, Val Loss: 0.7630, Val Acc:0.5887 | AUC: 0.8866, EER: 20.51% (thr=1.3564), Macro EER: 17.55%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 101. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/10:   1%|          | 1/100 [00:12<20:18, 12.31s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 100 that is less than the current step 102. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/10:   2%|▏         | 2/100 [00:24<19:48, 12.12s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 101 that is less than the current step 102. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 2/10: 100%|██████████| 100/100 [19:45<00:00, 11.86s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [04:57<00:00, 11.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 0.5360, Train Acc: 0.8116, Val Loss: 0.3876, Val Acc:0.8622 | AUC: 0.9508, EER: 12.48% (thr=0.5547), Macro EER: 7.89%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 201. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/10:   1%|          | 1/100 [00:11<19:34, 11.86s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 200 that is less than the current step 202. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/10:   2%|▏         | 2/100 [00:23<19:26, 11.90s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 201 that is less than the current step 202. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 3/10: 100%|██████████| 100/100 [19:35<00:00, 11.75s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [04:56<00:00, 11.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 0.4364, Train Acc: 0.8557, Val Loss: 0.3388, Val Acc:0.9138 | AUC: 0.9708, EER: 9.13% (thr=-1.5684), Macro EER: 5.27%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 300 that is less than the current step 301. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/10:   1%|          | 1/100 [00:12<20:03, 12.15s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 300 that is less than the current step 302. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/10:   2%|▏         | 2/100 [00:24<19:37, 12.01s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 301 that is less than the current step 302. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 4/10: 100%|██████████| 100/100 [19:21<00:00, 11.61s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [04:56<00:00, 11.88s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss: 0.3553, Train Acc: 0.8889, Val Loss: 0.3437, Val Acc:0.8609 | AUC: 0.9750, EER: 8.04% (thr=1.2041), Macro EER: 5.45%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 401. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/10:   1%|          | 1/100 [00:11<18:25, 11.16s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 400 that is less than the current step 402. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/10:   2%|▏         | 2/100 [00:22<18:48, 11.52s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 401 that is less than the current step 402. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 5/10: 100%|██████████| 100/100 [19:35<00:00, 11.75s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [04:53<00:00, 11.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.3315, Train Acc: 0.8942, Val Loss: 0.2943, Val Acc:0.9254 | AUC: 0.9814, EER: 7.25% (thr=-1.6426), Macro EER: 4.66%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 500 that is less than the current step 501. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/10:   1%|          | 1/100 [00:12<20:17, 12.29s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 500 that is less than the current step 502. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/10:   2%|▏         | 2/100 [00:24<19:43, 12.08s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 501 that is less than the current step 502. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 6/10: 100%|██████████| 100/100 [19:35<00:00, 11.75s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [04:52<00:00, 11.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss: 0.3124, Train Acc: 0.9017, Val Loss: 0.2993, Val Acc:0.9251 | AUC: 0.9830, EER: 6.72% (thr=-1.8662), Macro EER: 4.43%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 601. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/10:   1%|          | 1/100 [00:12<20:17, 12.30s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 600 that is less than the current step 602. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/10:   2%|▏         | 2/100 [00:24<19:42, 12.06s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 601 that is less than the current step 602. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 7/10: 100%|██████████| 100/100 [19:15<00:00, 11.55s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [04:48<00:00, 11.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss: 0.2785, Train Acc: 0.9143, Val Loss: 0.2084, Val Acc:0.9412 | AUC: 0.9855, EER: 6.19% (thr=-0.7051), Macro EER: 4.30%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 700 that is less than the current step 701. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/10:   1%|          | 1/100 [00:11<19:11, 11.64s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 700 that is less than the current step 702. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/10:   2%|▏         | 2/100 [00:22<18:31, 11.34s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 701 that is less than the current step 702. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 8/10: 100%|██████████| 100/100 [19:10<00:00, 11.50s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [04:47<00:00, 11.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss: 0.2472, Train Acc: 0.9248, Val Loss: 0.2294, Val Acc:0.9399 | AUC: 0.9869, EER: 6.31% (thr=-1.5547), Macro EER: 4.74%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 801. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 9/10:   1%|          | 1/100 [00:12<19:54, 12.07s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 800 that is less than the current step 802. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 9/10:   2%|▏         | 2/100 [00:23<19:25, 11.89s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 801 that is less than the current step 802. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 9/10: 100%|██████████| 100/100 [19:00<00:00, 11.41s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [04:44<00:00, 11.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss: 0.2614, Train Acc: 0.9173, Val Loss: 0.2445, Val Acc:0.9039 | AUC: 0.9869, EER: 5.88% (thr=1.1104), Macro EER: 4.03%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 900 that is less than the current step 901. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 10/10:   1%|          | 1/100 [00:11<18:49, 11.41s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 900 that is less than the current step 902. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 10/10:   2%|▏         | 2/100 [00:23<18:55, 11.59s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 901 that is less than the current step 902. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
            "Epoch 10/10: 100%|██████████| 100/100 [18:57<00:00, 11.38s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [04:46<00:00, 11.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss: 0.2258, Train Acc: 0.9309, Val Loss: 0.2031, Val Acc:0.9292 | AUC: 0.9879, EER: 5.41% (thr=0.8394), Macro EER: 4.32%, min t-DCF: nan\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>curves/auc</td><td>▁▅▇▇██████</td></tr><tr><td>grad_norm/detection</td><td>▁▁▄▆█▁▇▃▆▃▁▂▂▃▂▂▂▂▂▁▁▅▂▄▃▂▂▃▁▁▂▂▃▂▂▃▃▁▃▁</td></tr><tr><td>grad_norm/fuse</td><td>▁▁▁▁▁▂▃▂▇▄▄▅▃▆▆▆▅█▄▃▄▅▇▄▄▄▂▁▄▆▃▄▅▂▂▆█▇▁▂</td></tr><tr><td>grad_norm/projection</td><td>▁▁▂▄▇▆█▁▆▂▃▃▇▆▅▃▂▄▃▃▃▃▂▂▂▃▁▃▃▂▆▄▆▂▂▄▃▂▂▄</td></tr><tr><td>lr/detection</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr/fuse</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr/projection</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/batch_loss</td><td>██▇█▇▄▆▄▄▃▅▂▂▃▃▃▃▂▂▃▂▂▂▂▃▁▂▂▃▂▂▄▅▁▁▃▁▁▁▁</td></tr><tr><td>train/nnz_neighbor_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>curves/auc</td><td>0.98786</td></tr><tr><td>grad_norm/detection</td><td>0.3364</td></tr><tr><td>grad_norm/fuse</td><td>1.04317</td></tr><tr><td>grad_norm/projection</td><td>0.03671</td></tr><tr><td>lr/detection</td><td>0.001</td></tr><tr><td>lr/fuse</td><td>0.001</td></tr><tr><td>lr/projection</td><td>0.001</td></tr><tr><td>train/batch_loss</td><td>0.1487</td></tr><tr><td>train/nnz_neighbor_rate</td><td>1</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">colab-177b0ca59e53-1020</strong> at: <a href='https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf/runs/ohw10zt7' target=\"_blank\">https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf/runs/ohw10zt7</a><br> View project at: <a href='https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf' target=\"_blank\">https://wandb.ai/avinash-saxena-san-jose-state-university/deepfake-audio-raf</a><br>Synced 5 W&B file(s), 40 media file(s), 32 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251002_090115-ohw10zt7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tried to log to step 1000 that is less than the current step 1001. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tried to log to step 1000 that is less than the current step 1002. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss and Accuracy Curves\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "tSpxCfF9dMoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.plot_training_curves()"
      ],
      "metadata": {
        "id": "m0-RKvBgDyRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.show_curves_inline(smooth=7)"
      ],
      "metadata": {
        "id": "88z1PgOMEdnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Predictions"
      ],
      "metadata": {
        "id": "gYn6UYPafS6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spoof Prediction"
      ],
      "metadata": {
        "id": "yxVrNxh_fWz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "file_name = \"10136.wav\"\n",
        "audio_path = \"/content/release_in_the_wild/\"+file_name\n",
        "\n",
        "df = pd.read_csv(\"/content/release_in_the_wild/meta.csv\")\n",
        "expected = df[df[\"file\"]==file_name]\n",
        "\n",
        "\n",
        "# 12. Single-file prediction on GPU\n",
        "result = pipeline.predict(audio_path)\n",
        "\n",
        "filtered_df = df[df[\"file\"].isin(result['retrieved_files'])]\n",
        "\n",
        "\n",
        "print(f\"Prediction  : {result['prediction']}, Expected: {expected['label'].values[0]}, Speaker: {expected['speaker'].values[0]}\")\n",
        "print(f\"Probability Spoof: {result['probability_spoof']:.4f}\")\n",
        "print(\"Similar Audio Files retrieved\")\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "id": "u9iyjuWEr_5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2faec196-fd9e-42ef-d480-2133d6a887aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction  : spoof, Expected: spoof, Speaker: Alec Guinness\n",
            "Probability Spoof: 0.9414\n",
            "Similar Audio Files retrieved\n",
            "            file                speaker  label\n",
            "8551    8551.wav  Arnold Schwarzenegger  spoof\n",
            "15187  15187.wav          Alec Guinness  spoof\n",
            "21971  21971.wav               Ayn Rand  spoof\n",
            "25803  25803.wav               Ayn Rand  spoof\n",
            "29585  29585.wav          Alec Guinness  spoof\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonafide Prediction"
      ],
      "metadata": {
        "id": "Fvru2HiFfbC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"10135.wav\"\n",
        "audio_path = \"/content/release_in_the_wild/\"+file_name\n",
        "\n",
        "df = pd.read_csv(\"/content/release_in_the_wild/meta.csv\")\n",
        "expected = df[df[\"file\"]==file_name]\n",
        "\n",
        "\n",
        "# 12. Single-file prediction on GPU\n",
        "result = pipeline.predict(audio_path)\n",
        "\n",
        "filtered_df = df[df[\"file\"].isin(result['retrieved_files'])]\n",
        "\n",
        "\n",
        "print(f\"Prediction  : {result['prediction']}, Expected: {expected['label'].values[0]}, Speaker: {expected['speaker'].values[0]}\")\n",
        "print(f\"Probability Spoof: {result['probability_spoof']:.4f}\")\n",
        "print(\"Similar Audio Files retrieved\")\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiJBQ0EpeAA4",
        "outputId": "d183bbfe-e0cd-4f4e-bb8e-ffa2333771f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction  : bona-fide, Expected: bona-fide, Speaker: Barack Obama\n",
            "Probability Spoof: 0.1082\n",
            "Similar Audio Files retrieved\n",
            "            file       speaker      label\n",
            "3019    3019.wav  Barack Obama  bona-fide\n",
            "5376    5376.wav  Barack Obama  bona-fide\n",
            "7594    7594.wav  Barack Obama  bona-fide\n",
            "7666    7666.wav  Barack Obama  bona-fide\n",
            "21007  21007.wav  Barack Obama  bona-fide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "logCgOGoedFe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}