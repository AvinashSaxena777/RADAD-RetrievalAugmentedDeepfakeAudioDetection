{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fDuiWQC2kZId",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "fDuiWQC2kZId",
        "outputId": "926d5580-c4f7-4ece-b88a-7e99503b9bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-gpu-cu11==1.10.0\n",
            "  Downloading faiss_gpu_cu11-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2 (from faiss-gpu-cu11==1.10.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu11==1.10.0) (25.0)\n",
            "Collecting nvidia-cuda-runtime-cu11>=11.8.89 (from faiss-gpu-cu11==1.10.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cublas-cu11>=11.11.3.6 (from faiss-gpu-cu11==1.10.0)\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Downloading faiss_gpu_cu11-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, numpy, faiss-gpu-cu11\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed faiss-gpu-cu11-1.10.0 numpy-1.26.4 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-runtime-cu11-11.8.89\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "69041148dc5d4b4b9b051438aab93499",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install faiss-gpu-cu11==1.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "_17a-5LcVwzj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "8e5926fb78d243fb9e5933ee11a9ea2c",
            "eea5fe8fd0ee4633b8fb0f733ef3d175",
            "b9c40bb8486449a597da47045e385c98",
            "d6da89d1463f45f0bd031de4c73d3927",
            "dd25deae4e4e416cb048b560a56045da",
            "0149ca35b7d142b28e415194817e3676",
            "162a153051e5428aac33d7b28ddaca32",
            "056b54c3275a4348bd96cbf35dec4267",
            "7999fde0ef59444eae6a531f5966c5a1",
            "713e62bbe4bc49ce92c948671a6a42d3",
            "1a15caf2cdf64b5ebf6c34014289cccf"
          ]
        },
        "id": "_17a-5LcVwzj",
        "outputId": "62ca5fd9-298e-4a70-c7bf-2e76677a3df9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e5926fb78d243fb9e5933ee11a9ea2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature dimension set to: 768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Vector DB Build: 100%|██████████| 199/199 [06:01<00:00,  1.82s/it]\n",
            "Epoch 1/5: 100%|██████████| 100/100 [05:46<00:00,  3.47s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [01:33<00:00,  3.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss: 0.8185, Train Acc: 0.6178, Val Loss: 0.7604, Val Acc:0.7193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/5: 100%|██████████| 100/100 [05:42<00:00,  3.42s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [01:24<00:00,  3.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Train Loss: 0.7362, Train Acc: 0.6954, Val Loss: 0.6800, Val Acc:0.7344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5: 100%|██████████| 100/100 [05:37<00:00,  3.38s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [01:24<00:00,  3.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Train Loss: 0.6925, Train Acc: 0.7224, Val Loss: 0.6470, Val Acc:0.7395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/5: 100%|██████████| 100/100 [05:36<00:00,  3.37s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [01:24<00:00,  3.37s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Train Loss: 0.6856, Train Acc: 0.7255, Val Loss: 0.6303, Val Acc:0.7520\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/5: 100%|██████████| 100/100 [05:36<00:00,  3.36s/it]\n",
            "Evaluating: 100%|██████████| 25/25 [01:23<00:00,  3.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Train Loss: 0.6342, Train Acc: 0.7563, Val Loss: 0.6258, Val Acc:0.7819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "from config import Config\n",
        "from dataset import AudioDataset\n",
        "import argparse\n",
        "import os\n",
        "from pipeline import DeepfakeDetectionPipeline\n",
        "import torch\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run the complete audio deepfake detection pipeline.\"\"\"\n",
        "    # Configure logging\n",
        "    logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "\n",
        "    # 2. Parse command-line arguments\n",
        "    # parser = argparse.ArgumentParser(description=\"Audio Deepfake Detection\")\n",
        "    # parser.add_argument(\"--data_fraction\", type=float, default=1.0,\n",
        "    #                     help=\"Fraction of data to use (e.g., 0.25 for 25%)\")\n",
        "    # parser.add_argument(\"--mode\", type=str,\n",
        "    #                     choices=[\"train\", \"evaluate\", \"predict\"], required=True,\n",
        "    #                     help=\"Operation mode: train, evaluate, or predict\")\n",
        "    # parser.add_argument(\"--model_prefix\", type=str, default=\"final_model\",\n",
        "    #                     help=\"Prefix for saved model files\")\n",
        "    # parser.add_argument(\"--audio_path\", type=str,\n",
        "    #                     help=\"Path to audio file for prediction (required for predict mode)\")\n",
        "    # parser.add_argument(\"--device\", type=str, default=\"cuda:0\",\n",
        "    #                     help=\"Torch device for computation (e.g. cuda:0)\")\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    data_fraction = 0.5\n",
        "    mode = \"train\"\n",
        "    model_prefix = \"final_model\"\n",
        "    # args.audio_path = \"/content/release_in_the_wild/1008.wav\"\n",
        "\n",
        "    # 3. Disable problematic torchaudio backends\n",
        "    os.environ[\"TORCHAUDIO_USE_SOX\"] = \"0\"\n",
        "    os.environ[\"TORCHAUDIO_USE_BACKEND_DISPATCHER\"] = \"1\"\n",
        "\n",
        "    # 4. Set device\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    torch.cuda.set_device(device)\n",
        "\n",
        "    # 5. Create configuration\n",
        "    config = Config()\n",
        "    config.device = device\n",
        "    config.data_fraction = 0.5\n",
        "    config.train_split = 0.8\n",
        "\n",
        "    # 6. Choose appropriate DataLoader settings\n",
        "    config.num_workers = max(1, torch.cuda.device_count() * 2)\n",
        "    config.train_batch_size = getattr(config, \"train_batch_size\", 128)\n",
        "    config.eval_batch_size = getattr(config, \"eval_batch_size\", 128)\n",
        "    config.db_batch_size = getattr(config, \"db_batch_size\", 64)\n",
        "    config.top_k = getattr(config, \"top_k\", 5)\n",
        "    config.use_batch_norm = False\n",
        "    config.use_layer_norm = True\n",
        "\n",
        "    # 7. Initialize pipeline (moves all models to GPU)\n",
        "    pipeline = DeepfakeDetectionPipeline(config)\n",
        "\n",
        "    if mode == \"train\":\n",
        "        # 8. Instantiate datasets once with split flag\n",
        "        train_dataset = AudioDataset(config, is_train=True, split_data=True)\n",
        "        val_dataset   = AudioDataset(config, is_train=False, split_data=True)\n",
        "\n",
        "        # 9. Train with mixed-precision and GPU batching\n",
        "        pipeline.train(train_dataset, val_dataset)\n",
        "\n",
        "    elif mode == \"evaluate\":\n",
        "        # 10. Load best model onto GPU\n",
        "        pipeline.load_models(model_prefix)\n",
        "        pipeline.vector_db.load()\n",
        "\n",
        "        test_dataset = AudioDataset(config, is_train=False, split_data=False)\n",
        "        metrics = pipeline.evaluate_with_metrics(test_dataset)\n",
        "\n",
        "        print(\"Evaluation metrics:\")\n",
        "        for key, value in metrics.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "    elif mode == \"predict\":\n",
        "        if not audio_path:\n",
        "            raise ValueError(\"Audio path must be provided for predict mode\")\n",
        "\n",
        "        # 11. Load model & DB on GPU\n",
        "        pipeline.load_models(model_prefix)\n",
        "        pipeline.vector_db.load()\n",
        "\n",
        "        # 12. Single-file prediction on GPU\n",
        "        result = pipeline.predict(audio_path)\n",
        "        logging.info(f\"Prediction  : {result['prediction']}\")\n",
        "        logging.info(f\"Probability : {result['probability']:.4f}\")\n",
        "        logging.info(f\"Retrieved   : {result['retrieved_labels']}\")\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X3_RMWSyWG9S",
      "metadata": {
        "id": "X3_RMWSyWG9S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0149ca35b7d142b28e415194817e3676": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "056b54c3275a4348bd96cbf35dec4267": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "162a153051e5428aac33d7b28ddaca32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a15caf2cdf64b5ebf6c34014289cccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "713e62bbe4bc49ce92c948671a6a42d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7999fde0ef59444eae6a531f5966c5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e5926fb78d243fb9e5933ee11a9ea2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eea5fe8fd0ee4633b8fb0f733ef3d175",
              "IPY_MODEL_b9c40bb8486449a597da47045e385c98",
              "IPY_MODEL_d6da89d1463f45f0bd031de4c73d3927"
            ],
            "layout": "IPY_MODEL_dd25deae4e4e416cb048b560a56045da"
          }
        },
        "b9c40bb8486449a597da47045e385c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_056b54c3275a4348bd96cbf35dec4267",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7999fde0ef59444eae6a531f5966c5a1",
            "value": 1
          }
        },
        "d6da89d1463f45f0bd031de4c73d3927": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_713e62bbe4bc49ce92c948671a6a42d3",
            "placeholder": "​",
            "style": "IPY_MODEL_1a15caf2cdf64b5ebf6c34014289cccf",
            "value": " 1/1 [00:00&lt;00:00, 73.92it/s]"
          }
        },
        "dd25deae4e4e416cb048b560a56045da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea5fe8fd0ee4633b8fb0f733ef3d175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0149ca35b7d142b28e415194817e3676",
            "placeholder": "​",
            "style": "IPY_MODEL_162a153051e5428aac33d7b28ddaca32",
            "value": "Fetching 1 files: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
